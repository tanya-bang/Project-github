import requests
import pandas as pd
import os
from datetime import datetime, timedelta

# ì €ì¥ í´ë” ì„¤ì •
SAVE_PATH = "./naver_data/"
os.makedirs(SAVE_PATH, exist_ok=True)

# ë„¤ì´ë²„ ì¦ê¶Œ ì¢…ëª©í† ë¡  API ê¸°ë³¸ URL
DISCUSS_URL = "https://m.stock.naver.com/front-api/discuss"

# HTTP ìš”ì²­ í—¤ë”
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36",
    "Accept": "application/json"
}

# í¬ë¡¤ë§í•  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë° discussionType(global/local) êµ¬ë¶„
stocks = {
    "NVDA.O": {"name": "ì—”ë¹„ë””ì•„", "type": "globalStock"},
    "000660": {"name": "SKí•˜ì´ë‹‰ìŠ¤", "type": "localStock"},
    "TSLA.O": {"name": "í…ŒìŠ¬ë¼", "type": "globalStock"},
    "005930": {"name": "ì‚¼ì„±ì „ì", "type": "localStock"},
    "068270": {"name": "ì…€íŠ¸ë¦¬ì˜¨", "type": "localStock"},    
}

def load_existing_post_ids(file_path):
    # ì €ì¥ëœ post_id ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(file_path):
        df_existing = pd.read_csv(file_path, usecols=["post_id"], encoding="utf-8-sig")
        return set(df_existing["post_id"].dropna().astype(str))  
    return set()

def request_discussions(stock_code, discussion_type, rsno=None):
    # API ìš”ì²­ & json data ê°€ì ¸ì˜¤ê¸°
    params = {
        "discussionType": discussion_type,
        "itemCode": stock_code,
        "size": 20,  # ìµœì‹  20ê°œ ëŒ“ê¸€ ê°€ì ¸ì˜´
    }
    if rsno:
        params["rsno"] = rsno  # ì´ì „ ëŒ“ê¸€ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ìš”ì²­

    response = requests.get(DISCUSS_URL, params=params, headers=HEADERS)
    
    if response.status_code != 200:
        print(f"API ìš”ì²­ ì‹¤íŒ¨-ìƒíƒœ ì½”ë“œ: {response.status_code}")
        return []

    data = response.json()
    if not data.get("isSuccess"):
        print("API ì‘ë‹µ ì˜¤ë¥˜ ë°œìƒ")
        return None

    return data.get("result", [])


def process_discussions(results, start_datetime, end_datetime, existing_post_ids):
    # ì¤‘ì§€ ì¡°ê±´ ì„¤ì • ë° í•„í„°ë§, í†µê³¼í•œ data ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    discussions = []
    last_rsno = None
    stop_collection = False  # ì¤‘ì§€ ì¡°ê±´ 1)ì§€ì •ê¸°ê°„ 2)ê¸°ìˆ˜ì§‘ idì™€ ì¤‘ë³µ

    for post in results:
        post_date = datetime.strptime(post.get("date"), "%Y-%m-%d %H:%M:%S.%f")
        post_id = str(post.get("discussionId"))

        # ì¤‘ì§€ ì¡°ê±´ 1) ì§€ì •ëœ ìˆ˜ì§‘ ê¸°ê°„ ì´ì „ ë°ì´í„° ë°œê²¬
        if post_date < start_datetime:
            print(f"ğŸ”´ì§€ì •ëœ ì‹œê°„ ì´ì „ ë°ì´í„°({post_date})ë°œê²¬")
            stop_collection = True
            break

        # ì¤‘ì§€ ì¡°ê±´ 2) ê¸°ìˆ˜ì§‘ idì™€ ì¤‘ë³µ
        if post_id in existing_post_ids:
            print(f"ğŸ”´ê¸°ì¡´ ë°ì´í„°({post_id}) ë°œê²¬")
            stop_collection = True
            break

        # ë¦¬ìŠ¤íŠ¸ì— ìˆ˜ì§‘ëœ ë°ì´í„° ì¶”ê°€
        discussions.append({
            "platform": "ë„¤ì´ë²„ì¦ê¶Œ",
            "stock_name": stocks[post["itemCode"]]["name"],
            "post_id": post_id,
            "title": post.get("title"),
            "content": post.get("contents"),
            "timestamp": post.get("date")
        })

        last_rsno = post.get("rsno")  # ê°€ì¥ ì˜¤ë˜ëœ ê¸€ì˜ rsno ì €ì¥ - APIìš”ì²­ ìœ„í•œ ì •ë³´

    return discussions, last_rsno, stop_collection


def save_to_csv(file_path, all_diss):
    df = pd.DataFrame(all_diss, columns=["platform", "stock_name", "post_id", "title", "content", "timestamp"])
    df = df.sort_values(by="timestamp", ascending=True)

    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    file_exists = os.path.exists(file_path)
    df.to_csv(file_path, index=False, encoding="utf-8-sig", mode="a", header=not file_exists)
    print(f"ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path} / ìƒˆë¡œìš´ ê¸€ {len(all_diss)}ê°œ í™•ì¸")


def collect_discussions(stock_code, discussion_type, start_datetime, end_datetime):
    # ì¢…ëª©ë³„ ê¸€ ì‹¤ì œ ìˆ˜ì§‘ ë° ì €ì¥
    stock_name = stocks[stock_code]["name"]
    file_path = os.path.join(SAVE_PATH, f"naver_{stock_name}.csv")
    
    existing_post_ids = load_existing_post_ids(file_path)
    rsno = None  
    all_diss = []  # ëª¨ë“  API ìš”ì²­ì˜ ë°ì´í„°ë¥¼ ëª¨ì•„ë‘ëŠ” ë¦¬ìŠ¤íŠ¸

    while True:
        results = request_discussions(stock_code, discussion_type, rsno)
        if not results:
            print(f"ë” ì´ìƒ ê°€ì ¸ì˜¬ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ({stock_code})")
            break

        discussions, rsno, stop_collection = process_discussions(results, start_datetime, end_datetime, existing_post_ids)

        if discussions:
            all_diss.extend(discussions)  # API 1íšŒ ìš”ì²­ ìˆ˜ì§‘ data ì¶”ê°€

        if stop_collection:  # ì¤‘ì§€ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ ì¦‰ì‹œ ì¢…ë£Œ
            break

    if all_diss:
        save_to_csv(file_path, all_diss)


def run_scrap(hours_ago):
    """ ì „ì²´ ì¢…ëª©ì— ëŒ€í•´ ëŒ“ê¸€ì„ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜ """
    start_datetime = datetime.now() - timedelta(hours=hours_ago)
    end_datetime = datetime.now()

    for stock_code, info in stocks.items():
        print(f"ğŸ” {info['name']} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        collect_discussions(stock_code, info["type"], start_datetime, end_datetime)

# ì‹¤í–‰
run_scrap(hours_ago=72)
